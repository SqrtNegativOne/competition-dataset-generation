{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8255acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcaf7517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private dataset: 70.000000%\n",
      "Public train dataset: 24.000000%\n",
      "Public test dataset: 6.000000%\n",
      "Public train dataset size: 7200\n"
     ]
    }
   ],
   "source": [
    "SEED = 42 # answer to everything\n",
    "\n",
    "N_SAMPLES = 30000\n",
    "PUBLIC_PRIVATE_SPLIT = 0.3 # Fraction of samples used for the public dataset\n",
    "TEST_TRAIN_SPLIT = 0.2 # Fraction of samples used for the test set\n",
    "print(f\"Private dataset: {(1 - PUBLIC_PRIVATE_SPLIT) * 100:1f}%\\nPublic train dataset: {PUBLIC_PRIVATE_SPLIT * (1 - TEST_TRAIN_SPLIT) * 100:1f}%\\nPublic test dataset: {PUBLIC_PRIVATE_SPLIT * TEST_TRAIN_SPLIT * 100:1f}%\")\n",
    "print(f\"Public train dataset size: {int(N_SAMPLES * PUBLIC_PRIVATE_SPLIT * (1 - TEST_TRAIN_SPLIT))}\")\n",
    "\n",
    "INITIAL_NOISE = 0.1 # Previously was 0.3\n",
    "FINAL_NOISE = 0.05 # Added to the final target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import (\n",
    "    make_moons, make_circles, make_blobs, make_classification, make_hastie_10_2,\n",
    "    make_friedman1, make_friedman2, make_friedman3, make_regression\n",
    ")\n",
    "from typing import Callable\n",
    "\n",
    "class ds:\n",
    "    def __init__(self, weight: float, name: str, generator: Callable[[], tuple[np.ndarray, np.ndarray]]):\n",
    "        self.weight: float = weight\n",
    "        self.name: str = name\n",
    "\n",
    "        X: np.ndarray\n",
    "        y: np.ndarray\n",
    "        X, y = generator()\n",
    "        self.X: pd.DataFrame = pd.DataFrame(X, columns=[f\"{self.name}_{i}\" for i in range(X.shape[1])])\n",
    "        self.y: pd.Series = pd.Series(y, name=\"{self.name}_y\")\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, ds) and self.name == other.name\n",
    "\n",
    "# Make sure each has a unique name.\n",
    "DATASETS: list[ds] = [\n",
    "    ds(4, \"moon\",      lambda: make_moons(n_samples=N_SAMPLES, noise=INITIAL_NOISE, random_state=SEED)),\n",
    "    ds(3, \"circle\",    lambda: make_circles(n_samples=N_SAMPLES, noise=INITIAL_NOISE, factor=0.6, random_state=SEED)),\n",
    "    ds(2, \"blob\",      lambda: make_blobs(n_samples=N_SAMPLES, centers=3, n_features=2, random_state=SEED, return_centers=False)), # type: ignore # return_centers=False to avoid returning centers\n",
    "    ds(2, \"hastie\",    lambda: make_hastie_10_2(n_samples=N_SAMPLES, random_state=SEED)),\n",
    "    ds(2, \"friedman1\", lambda: make_friedman1(n_samples=N_SAMPLES, noise=INITIAL_NOISE, random_state=SEED)),\n",
    "    ds(2, \"friedman2\", lambda: make_friedman2(n_samples=N_SAMPLES, noise=INITIAL_NOISE, random_state=SEED)),\n",
    "    ds(2, \"friedman3\", lambda: make_friedman3(n_samples=N_SAMPLES, noise=INITIAL_NOISE, random_state=SEED)),\n",
    "    ds(1, \"class\",     lambda: make_classification(n_samples=N_SAMPLES, n_features=5, n_informative=3, n_redundant=1, random_state=SEED)),\n",
    "    ds(1, \"reg\",       lambda: make_regression(n_samples=N_SAMPLES, n_features=5, n_informative=3, noise=INITIAL_NOISE, random_state=SEED, coef=False)), # type: ignore # coef=False to avoid returning coefficients\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04398806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([d.X for d in DATASETS], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_weights = np.array([d.weight for d in DATASETS], dtype=np.float64) # dtype=np.float64 for division in the next line\n",
    "normalized_weights /= normalized_weights.sum()\n",
    "y_final = sum(DATASETS[i].y * normalized_weights[i] for i in range(len(DATASETS)))\n",
    "y_final += np.random.normal(0, FINAL_NOISE, size= N_SAMPLES) # Some small, random noise to the final target\n",
    "df['y'] = y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4fb625c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to data_09_15-42-21.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "output_path = f\"data_{timestamp}.csv\"\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
